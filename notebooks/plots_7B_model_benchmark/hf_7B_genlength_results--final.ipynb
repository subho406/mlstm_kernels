{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from mlstm_kernels.utils.benchmark.plot_results import (\n",
    "    plot_benchmark_result_table,\n",
    "    rc_context_wrapper,\n",
    "    select_columns,\n",
    ")\n",
    "from pathlib import Path\n",
    "from plot_config import linestyle_mapping, style_dict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results batch size 1\n",
    "falconmamba_gen_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-05_13-57-50__gen_time__gentime_falconmamba_cgmtrue_v0/hf_7B_generation_time__pfl0_bs1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "codestralmamba_gen_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-05_15-43-18__gen_time__codestral_mamba_gen_cgmtrue_v0/hf_7B_generation_time__pfl0_bs1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "mxlstmmamba_gen_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-05_08-42-43__gen_time__genttime_xlstm_v1/hf_7B_generation_time__pfl0_bs1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "llama_gen_file = \"/home/beck/wdir/dev_repos/mlstm_kernels/outputs_kernel_benchmarks_final/2024-12-05_15-20-04__gen_time__llama_static_v0/hf_7B_generation_time__pfl0_bs1_tcTrue_weightdtypebfloat16/results.csv\"\n",
    "\n",
    "file_dict = {\n",
    "    \"falconmamba\": falconmamba_gen_file,\n",
    "    \"codestralmamba\": codestralmamba_gen_file,\n",
    "    \"llama\": llama_gen_file,\n",
    "    \"mxlstmmamba\": mxlstmmamba_gen_file,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict = {\n",
    "    k: (\n",
    "        pd.read_csv(v).filter(regex=\".*generation|.*R--.*\"),\n",
    "        pd.read_csv(v).filter(regex=\".*generation|.*M--.*\"),\n",
    "    )\n",
    "    for k, v in file_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_time_df = pd.concat([v[0] for v in dataframe_dict.values()], axis=1)\n",
    "gen_time_df = pd.concat(\n",
    "    [\n",
    "        gen_time_df.filter(regex=\".*generation.*\").take([0], axis=1),\n",
    "        gen_time_df.filter(regex=\".*R--.*\") / 1e3,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "gen_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mem_df = pd.concat([v[1] for v in dataframe_dict.values()], axis=1)\n",
    "gen_mem_df = pd.concat(\n",
    "    [\n",
    "        gen_mem_df.filter(regex=\".*generation.*\").take([0], axis=1),\n",
    "        gen_mem_df.filter(regex=\".*M--.*\") / 1e9,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "gen_mem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "    \"gen_time_seconds\": gen_time_df,\n",
    "    \"gen_mem_gb\": gen_mem_df,\n",
    "}\n",
    "with open(\"gen_time_mem_data.p\", \"wb\") as f:\n",
    "    pickle.dump(raw_data, f)\n",
    "\n",
    "for k, v in raw_data.items():\n",
    "    v.to_csv(f\"raw_data_{k}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_benchmark_result_table(\n",
    "    gen_time_df,\n",
    "    x_axis_param=\"generation_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    # style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Time [s]\",\n",
    "    title=\"Time to generate X tokens, no prefill\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_benchmark_result_table(\n",
    "    gen_mem_df,\n",
    "    x_axis_param=\"generation_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    # style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Memory GB\",\n",
    "    title=\"Time to generate X tokens, no prefill\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Plots - All results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_runtime = {\n",
    "    \"llama3\": \"R--llama3__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-False\",\n",
    "    \"llama2\": \"R--llama2__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-False\",\n",
    "    \"falcon_mamba\": \"R--falcon_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-True\",\n",
    "    \"codestral_mamba\": \"R--codestral_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-True\",\n",
    "    \"xlstm\": \"R--xlstm__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-True_isd-bfloat16_ed-4096_nh-8_nb-32_vs-50304_wm-fused_ck-chunkwise--triton_xl_chunk_sk-native_sequence__triton_step_fused_sk-triton_fused_cs-128_akd-bfloat16\",\n",
    "}\n",
    "selected_columns_memory = {\n",
    "    \"llama2\": \"M--llama2__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-False\",\n",
    "    \"llama3\": \"M--llama3__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-False\",\n",
    "    \"falcon_mamba\": \"M--falcon_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-True\",\n",
    "    \"codestral_mamba\": \"M--codestral_mamba__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-True\",\n",
    "    \"xlstm\": \"M--xlstm__tcm__ampdt-bfloat16__wdt-bfloat16__ucgg-False_ucgm-True_isd-bfloat16_ed-4096_nh-8_nb-32_vs-50304_wm-fused_ck-chunkwise--triton_xl_chunk_sk-native_sequence__triton_step_fused_sk-triton_fused_cs-128_akd-bfloat16\",\n",
    "}\n",
    "filename_suffix = \"\"\n",
    "add_legend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_time_plot_df = select_columns(\n",
    "    gen_time_df, selected_columns_runtime, keep_col_regex=\".*generation.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rc_context_wrapper(\n",
    "    func=plot_benchmark_result_table,\n",
    "    result_df=gen_time_plot_df,\n",
    "    x_axis_param=\"generation_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"Generation Time [s]\",\n",
    "    x_label=\"Generated Tokens\",\n",
    "    title=\"\",  # \"Time to generate 1 tokens, for varying prefill lengths\",\n",
    "    figsize=(1.5 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "    filename=f\"generation_time{filename_suffix}\",\n",
    "    add_legend=add_legend,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mem_plot_df = select_columns(\n",
    "    gen_mem_df, selected_columns_memory, keep_col_regex=\".*generation.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rc_context_wrapper(\n",
    "    func=plot_benchmark_result_table,\n",
    "    result_df=gen_mem_plot_df,\n",
    "    x_axis_param=\"generation_length\",\n",
    "    # linestyle_mapping=linestyle_mapping,\n",
    "    style_dict=style_dict,\n",
    "    style_dict_colname_mapping_exact=False,\n",
    "    y_label=\"GPU Memory [GB]\",\n",
    "    x_label=\"Generation Length\",\n",
    "    title=\"\",  # \"Time to generate 100 tokens, for varying prefill lengths\",\n",
    "    figsize=(1.5 * 12 * 1 / 2.54, 1.5 * 8 * 1 / 2.54),\n",
    "    filename=f\"generation_memory{filename_suffix}\",\n",
    "    add_legend=add_legend,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm_speed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
